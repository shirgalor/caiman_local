{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ba2717",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/shirgalor/caiman_local/blob/main/CNMF_Colab_Runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a70bf",
   "metadata": {},
   "source": [
    "# CNMF Analysis in Google Colab\n",
    "## Your Custom CaImAn CNMF Project\n",
    "\n",
    "This notebook runs your specific CNMF project with all custom modifications:\n",
    "- Custom debug stage saving\n",
    "- Error handling for spatial/temporal updates  \n",
    "- YrA error filtering\n",
    "- Manual step-by-step CNMF execution\n",
    "\n",
    "**Runtime Requirements:** Use GPU runtime for faster processing (though CNMF is CPU-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a388b05",
   "metadata": {},
   "source": [
    "## üì¶ Setup: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff267b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CaImAn and dependencies\n",
    "!pip install caiman[complete] -q\n",
    "!pip install tifffile matplotlib -q\n",
    "\n",
    "# Install additional packages for visualization\n",
    "!pip install seaborn plotly -q\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0467d7c",
   "metadata": {},
   "source": [
    "## üíæ Setup: Mount Google Drive & Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67594c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create output directories\n",
    "output_dir = '/content/drive/MyDrive/cnmf_colab_output'\n",
    "local_output = '/content/cnmf_local_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(local_output, exist_ok=True)\n",
    "os.makedirs('/content/data', exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Output directories created:\")\n",
    "print(f\"  - Google Drive: {output_dir}\")\n",
    "print(f\"  - Local (faster): {local_output}\")\n",
    "print(f\"  - Data directory: /content/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee03bb9a",
   "metadata": {},
   "source": [
    "## üìπ Upload Your Video File\n",
    "\n",
    "**Choose one option:**\n",
    "1. **Upload directly** (run the cell below)\n",
    "2. **Use from Google Drive** (modify the path in the next cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e563db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload video file directly to Colab\n",
    "print(\"üìπ Please upload your TIF video file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded file to data directory\n",
    "video_filename = None\n",
    "for filename in uploaded.keys():\n",
    "    if filename.lower().endswith(('.tif', '.tiff')):\n",
    "        video_path = f'/content/data/{filename}'\n",
    "        shutil.move(filename, video_path)\n",
    "        video_filename = filename\n",
    "        print(f\"‚úÖ Video uploaded: {video_path}\")\n",
    "        print(f\"üìä File size: {os.path.getsize(video_path) / (1024**3):.2f} GB\")\n",
    "        break\n",
    "\n",
    "if video_filename is None:\n",
    "    print(\"‚ùå No TIF file found in upload. Please upload a TIF/TIFF file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Use video file from Google Drive\n",
    "# Uncomment and modify the path below if you have the video in Google Drive\n",
    "\n",
    "# drive_video_path = '/content/drive/MyDrive/your_video_file.tif'  # MODIFY THIS PATH\n",
    "# \n",
    "# if os.path.exists(drive_video_path):\n",
    "#     video_path = '/content/data/video_file.tif'\n",
    "#     shutil.copy(drive_video_path, video_path)\n",
    "#     print(f\"‚úÖ Video copied from Drive: {video_path}\")\n",
    "#     print(f\"üìä File size: {os.path.getsize(video_path) / (1024**3):.2f} GB\")\n",
    "# else:\n",
    "#     print(f\"‚ùå Video file not found at: {drive_video_path}\")\n",
    "#     print(\"üìÅ Available files in your Drive:\")\n",
    "#     !find '/content/drive/MyDrive' -name '*.tif' -o -name '*.TIF' | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebda3b6",
   "metadata": {},
   "source": [
    "## üîç System Check: Memory & Video Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6211a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "\n",
    "def check_system_resources():\n",
    "    \"\"\"Check available system resources\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    cpu_count = psutil.cpu_count()\n",
    "    \n",
    "    print(\"üñ•Ô∏è System Resources:\")\n",
    "    print(f\"  üíæ Total RAM: {memory.total / (1024**3):.1f} GB\")\n",
    "    print(f\"  üíæ Available RAM: {memory.available / (1024**3):.1f} GB\")\n",
    "    print(f\"  üîß CPU Cores: {cpu_count}\")\n",
    "    \n",
    "    return memory.available / (1024**3)\n",
    "\n",
    "def check_video_info(video_path):\n",
    "    \"\"\"Check video file information and memory requirements\"\"\"\n",
    "    try:\n",
    "        # Read just the header to get dimensions\n",
    "        with open(video_path, 'rb') as f:\n",
    "            # Try to read video info without loading full file\n",
    "            pass\n",
    "        \n",
    "        # Load a small sample to get info\n",
    "        print(\"üìπ Analyzing video file...\")\n",
    "        Y_sample = imread(video_path, key=slice(0, 10))  # Read first 10 frames\n",
    "        sample_frames, d1, d2 = Y_sample.shape\n",
    "        \n",
    "        # Estimate total frames (this is approximate)\n",
    "        file_size = os.path.getsize(video_path)\n",
    "        bytes_per_frame = Y_sample.nbytes / sample_frames\n",
    "        estimated_total_frames = int(file_size / bytes_per_frame)\n",
    "        \n",
    "        print(f\"üìä Video Information:\")\n",
    "        print(f\"  üìê Dimensions: {d1} x {d2} pixels\")\n",
    "        print(f\"  üé¨ Estimated frames: ~{estimated_total_frames}\")\n",
    "        print(f\"  üíæ Estimated RAM needed: ~{(estimated_total_frames * d1 * d2 * 4) / (1024**3):.1f} GB\")\n",
    "        \n",
    "        return estimated_total_frames, d1, d2\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading video: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Check system and video\n",
    "available_ram = check_system_resources()\n",
    "\n",
    "if 'video_path' in locals() and os.path.exists(video_path):\n",
    "    est_frames, d1, d2 = check_video_info(video_path)\n",
    "    \n",
    "    if est_frames and est_frames > 800:\n",
    "        print(f\"\\n‚ö†Ô∏è Large dataset detected ({est_frames} frames)\")\n",
    "        print(f\"üí° Consider limiting to first 600-800 frames for Colab\")\n",
    "        print(f\"üí° You can modify this in the next cell\")\n",
    "else:\n",
    "    print(\"‚ùå Video file not found. Please upload or set the correct path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896b8e6",
   "metadata": {},
   "source": [
    "## üß† Your Custom CNMF Code\n",
    "\n",
    "This cell contains your exact CNMF implementation with all modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99764970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tifffile import imread\n",
    "import warnings\n",
    "import sys\n",
    "from contextlib import redirect_stderr\n",
    "from io import StringIO\n",
    "import gc\n",
    "\n",
    "# Simple error suppression for YrA plotting issues\n",
    "def suppress_YrA_errors():\n",
    "    \"\"\"Suppress common YrA visualization errors\"\"\"\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*cannot reshape array.*\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*Failed to plot YrA.*\")\n",
    "\n",
    "suppress_YrA_errors()\n",
    "\n",
    "from caiman.source_extraction.cnmf import cnmf, params\n",
    "from caiman.mmapping import load_memmap, save_memmap\n",
    "\n",
    "# Create a custom output filter for YrA messages only\n",
    "class YrAErrorFilter:\n",
    "    def __init__(self, original_stream):\n",
    "        self.original_stream = original_stream\n",
    "        \n",
    "    def write(self, text):\n",
    "        # Only filter out specific YrA error messages, let everything else through\n",
    "        if (\"Failed to plot YrA\" in text and \"cannot reshape array\" in text):\n",
    "            # Replace YrA error with a cleaner message\n",
    "            self.original_stream.write(\"‚ö†Ô∏è YrA visualization skipped (shape mismatch)\\n\")\n",
    "        else:\n",
    "            self.original_stream.write(text)\n",
    "    \n",
    "    def flush(self):\n",
    "        self.original_stream.flush()\n",
    "        \n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.original_stream, name)\n",
    "\n",
    "# Manual debug saver that works without visualization\n",
    "class ManualDebugSaver:\n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "    \n",
    "    def save_stage(self, cnmf_obj, stage_name):\n",
    "        \"\"\"Save CNMF outputs at each stage without problematic visualization\"\"\"\n",
    "        print(f\"üì∏ Saving stage: {stage_name}\")\n",
    "        \n",
    "        def save_array(name, arr, stage):\n",
    "            if arr is not None:\n",
    "                try:\n",
    "                    if hasattr(arr, 'toarray'):\n",
    "                        arr = arr.toarray()\n",
    "                    filename = os.path.join(self.output_dir, f\"{name}_{stage}.npy\")\n",
    "                    np.save(filename, arr)\n",
    "                    print(f\"  ‚úÖ Saved {name} shape {arr.shape} to {filename}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ùå Failed to save {name}: {e}\")\n",
    "        \n",
    "        # Save all matrices\n",
    "        if hasattr(cnmf_obj, 'estimates'):\n",
    "            save_array(\"A\", cnmf_obj.estimates.A, stage_name)\n",
    "            save_array(\"C\", cnmf_obj.estimates.C, stage_name)\n",
    "            save_array(\"b\", cnmf_obj.estimates.b, stage_name)\n",
    "            save_array(\"f\", cnmf_obj.estimates.f, stage_name)\n",
    "            \n",
    "            # Save YrA properly as temporal data (don't try to visualize as image)\n",
    "            if hasattr(cnmf_obj.estimates, \"YrA\") and cnmf_obj.estimates.YrA is not None:\n",
    "                save_array(\"YrA\", cnmf_obj.estimates.YrA, stage_name)\n",
    "                print(f\"  üìä YrA shape: {cnmf_obj.estimates.YrA.shape} (K components √ó T timepoints)\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_path = os.path.join(self.output_dir, f\"metadata_{stage_name}.txt\")\n",
    "        with open(metadata_path, \"w\") as f:\n",
    "            f.write(f\"Stage: {stage_name}\\n\")\n",
    "            if hasattr(cnmf_obj, 'estimates'):\n",
    "                f.write(f\"A shape: {getattr(cnmf_obj.estimates.A, 'shape', 'None')}\\n\")\n",
    "                f.write(f\"C shape: {getattr(cnmf_obj.estimates.C, 'shape', 'None')}\\n\")\n",
    "                f.write(f\"YrA shape: {getattr(cnmf_obj.estimates.YrA, 'shape', 'None')}\\n\")\n",
    "            f.write(f\"dims: {getattr(cnmf_obj, 'dims', 'None')}\\n\")\n",
    "        print(f\"  üìù Saved metadata to {metadata_path}\")\n",
    "\n",
    "# ---------- Wrapper for CNMF Execution Without Manual Debug ----------\n",
    "\n",
    "class CNMFWrapper:\n",
    "    def __init__(self, cnmf_obj, mmap_path, dims, output_dir):\n",
    "        self.cnmf = cnmf_obj\n",
    "        self.mmap_path = mmap_path\n",
    "        self.dims = dims\n",
    "        self.debug_saver = ManualDebugSaver(output_dir)\n",
    "\n",
    "    def run(self):\n",
    "        # Filter YrA error messages during CNMF execution\n",
    "        original_stdout = sys.stdout\n",
    "        original_stderr = sys.stderr\n",
    "        sys.stdout = YrAErrorFilter(original_stdout)\n",
    "        sys.stderr = YrAErrorFilter(original_stderr)\n",
    "        \n",
    "        try:\n",
    "            # Load memmap data correctly\n",
    "            print(f\"üìñ Loading memmap from: {self.mmap_path}\")\n",
    "            \n",
    "            # Try CaImAn's load_memmap first\n",
    "            try:\n",
    "                Yr, dims_loaded, T = load_memmap(self.mmap_path)\n",
    "                dims = dims_loaded\n",
    "                print(f\"üìñ Loaded with load_memmap: Yr shape {Yr.shape}, dims={dims}, T={T}\")\n",
    "            except:\n",
    "                # Fallback: load directly as memmap\n",
    "                print(\"üìñ Using direct memmap loading...\")\n",
    "                T = self.dims[0] * self.dims[1]  # This will be corrected below\n",
    "                \n",
    "                # Load the memmap file directly\n",
    "                fp_in = np.memmap(self.mmap_path, dtype=np.float32, mode='r')\n",
    "                n_pixels = self.dims[0] * self.dims[1]\n",
    "                T = fp_in.shape[0] // n_pixels\n",
    "                \n",
    "                Yr = fp_in.reshape((n_pixels, T), order='F')\n",
    "                dims = self.dims\n",
    "                print(f\"üìñ Direct load: Yr shape {Yr.shape}, dims={dims}, T={T}\")\n",
    "            \n",
    "            self.cnmf.dims = self.dims\n",
    "            \n",
    "            # Ensure debug visualization is completely disabled\n",
    "            self.cnmf.debug_visualize = False\n",
    "            if hasattr(self.cnmf, '_debug_image'):\n",
    "                delattr(self.cnmf, '_debug_image')\n",
    "            \n",
    "            # Check if only initialization\n",
    "            only_init = self.cnmf.params.get('patch', 'only_init')\n",
    "            if only_init is None:\n",
    "                only_init = False\n",
    "            print(f\"üîß Running CNMF with only_init = {only_init}\")\n",
    "            \n",
    "            if only_init:\n",
    "                # For only_init=True, just do initialization\n",
    "                print(\"üöÄ Starting initialization only...\")\n",
    "                self.cnmf.fit_file(self.mmap_path)\n",
    "                self.debug_saver.save_stage(self.cnmf, \"after_init_only\")\n",
    "            else:\n",
    "                # Force manual step-by-step approach to save all debug stages\n",
    "                print(\"üöÄ Using manual step-by-step approach to save all debug stages...\")\n",
    "                \n",
    "                # Manual approach for complete debugging\n",
    "                # Load and preprocess data\n",
    "                print(\"üìñ Loading and preprocessing data...\")\n",
    "                Yr = self.cnmf.preprocess(Yr)\n",
    "                \n",
    "                # Initialization\n",
    "                print(\"üéØ Running initialization...\")\n",
    "                self.cnmf.initialize(Yr.reshape((-1, T), order='F'))\n",
    "                self.debug_saver.save_stage(self.cnmf, \"after_initialize\")\n",
    "                \n",
    "                # Spatial update 1\n",
    "                print(\"üó∫Ô∏è Running spatial update 1...\")\n",
    "                try:\n",
    "                    self.cnmf.update_spatial(Yr.reshape((-1, T), order='F'))\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_spatial_1\")\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Spatial update 1 failed: {e}\")\n",
    "                    print(\"‚ö†Ô∏è Skipping spatial update 1...\")\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_spatial_1_failed\")\n",
    "                \n",
    "                # Temporal update 1\n",
    "                print(\"‚è∞ Running temporal update 1...\")\n",
    "                try:\n",
    "                    self.cnmf.update_temporal(Yr.reshape((-1, T), order='F'))\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_temporal_1\")\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Temporal update 1 failed: {e}\")\n",
    "                    print(\"‚ö†Ô∏è Skipping temporal update 1...\")\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_temporal_1_failed\")\n",
    "                \n",
    "                # Merging (if enabled)\n",
    "                do_merge = self.cnmf.params.get('merging', 'do_merge')\n",
    "                if do_merge is None:\n",
    "                    do_merge = True\n",
    "                if do_merge:\n",
    "                    print(\"üîó Running component merging...\")\n",
    "                    try:\n",
    "                        self.cnmf.merge_comps(Yr.reshape((-1, T), order='F'))\n",
    "                        self.debug_saver.save_stage(self.cnmf, \"after_merge\")\n",
    "                    except (IndexError, ValueError) as e:\n",
    "                        print(f\"‚ö†Ô∏è Merging failed: {e}\")\n",
    "                        print(\"‚ö†Ô∏è Continuing without merging...\")\n",
    "                        # Save the stage anyway without merging\n",
    "                        self.debug_saver.save_stage(self.cnmf, \"after_merge_failed\")\n",
    "                \n",
    "                # Spatial update 2\n",
    "                print(\"üó∫Ô∏è Running spatial update 2...\")\n",
    "                try:\n",
    "                    self.cnmf.update_spatial(Yr.reshape((-1, T), order='F'))\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_spatial_2\")\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Spatial update 2 failed: {e}\")\n",
    "                    print(\"‚ö†Ô∏è Skipping spatial update 2...\")\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_spatial_2_failed\")\n",
    "                \n",
    "                # Temporal update 2\n",
    "                print(\"‚è∞ Running temporal update 2...\")\n",
    "                try:\n",
    "                    self.cnmf.update_temporal(Yr.reshape((-1, T), order='F'))\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_temporal_2\")\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Temporal update 2 failed: {e}\")\n",
    "                    print(\"‚ö†Ô∏è Skipping temporal update 2...\")\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"after_temporal_2_failed\")\n",
    "                \n",
    "                # Final residuals computation\n",
    "                print(\"üßÆ Computing final residuals...\")\n",
    "                try:\n",
    "                    self.cnmf.compute_residuals(Yr.reshape((-1, T), order='F'))\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"final\")\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"‚ö†Ô∏è Final residuals computation failed: {e}\")\n",
    "                    print(\"‚ö†Ô∏è Skipping residuals computation...\")\n",
    "                    self.debug_saver.save_stage(self.cnmf, \"final_no_residuals\")\n",
    "            \n",
    "            # Save final output\n",
    "            output_path = os.path.join(self.output_dir, \"cnmf_final_output.hdf5\")\n",
    "            self.cnmf.save(output_path)\n",
    "            print(f\"üíæ Saved final CNMF output to {output_path}\")\n",
    "            \n",
    "            print(\"A shape:\", self.cnmf.estimates.A.shape)\n",
    "            print(\"C shape:\", self.cnmf.estimates.C.shape)\n",
    "            print(\"Number of ROIs:\", self.cnmf.estimates.A.shape[1])\n",
    "            A_final = self.cnmf.estimates.A.toarray()\n",
    "            print(\"Non-zero in A:\", np.count_nonzero(A_final))\n",
    "            \n",
    "            return self.cnmf\n",
    "            \n",
    "        finally:\n",
    "            # Restore original streams\n",
    "            sys.stdout = original_stdout\n",
    "            sys.stderr = original_stderr\n",
    "\n",
    "print(\"‚úÖ CNMF code loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b834b99",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configure Parameters & Run CNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f77df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnmf_analysis(video_path, output_dir, limit_frames=None):\n",
    "    \"\"\"Run your complete CNMF analysis\"\"\"\n",
    "    \n",
    "    # Load video data\n",
    "    print(f\"üìñ Loading video from: {video_path}\")\n",
    "    Y = imread(video_path)\n",
    "    \n",
    "    # Optional: limit number of frames for Colab memory management\n",
    "    if limit_frames and Y.shape[0] > limit_frames:\n",
    "        print(f\"‚ö†Ô∏è Limiting frames from {Y.shape[0]} to {limit_frames} for Colab\")\n",
    "        Y = Y[:limit_frames]\n",
    "    \n",
    "    T, d1, d2 = Y.shape\n",
    "    dims = (d1, d2)\n",
    "    \n",
    "    print(f\"üìä Data info: {T} frames, {d1}x{d2} pixels\")\n",
    "    print(f\"üìä Data range: {Y.min()} to {Y.max()}\")\n",
    "    print(f\"üìä Data type: {Y.dtype}\")\n",
    "    print(f\"üìä Memory usage: ~{(Y.nbytes / 1024**3):.1f} GB\")\n",
    "\n",
    "    # Create memmap file\n",
    "    print(\"üìù Creating CaImAn-compatible memmap...\")\n",
    "    \n",
    "    mmap_base = f\"colab_d1_{d1}_d2_{d2}_frames_{T}\"\n",
    "    mmap_path = os.path.join(output_dir, mmap_base + '.mmap')\n",
    "    \n",
    "    # Convert to the right format and save\n",
    "    Y_reshaped = Y.astype(np.float32)\n",
    "    \n",
    "    # Create the memmap file directly in the expected format\n",
    "    fp_out = np.memmap(mmap_path, dtype=np.float32, mode='w+', \n",
    "                      shape=(np.prod(Y_reshaped.shape[1:]), Y_reshaped.shape[0]))\n",
    "    \n",
    "    # Reshape and transpose to get (pixels, time) format that CaImAn expects\n",
    "    for t in range(Y_reshaped.shape[0]):\n",
    "        fp_out[:, t] = Y_reshaped[t].flatten(order='F')\n",
    "    \n",
    "    fp_out.flush()\n",
    "    del fp_out, Y, Y_reshaped\n",
    "    gc.collect()  # Force garbage collection\n",
    "    \n",
    "    print(f\"üìÅ Created memmap: {mmap_path}\")\n",
    "\n",
    "    # Biological parameters (your exact settings)\n",
    "    fr = 1.08                               # imaging rate in frames per second\n",
    "    decay_time = 20                         # length of a typical transient in seconds \n",
    "    dxy = (1.243, 1.243)                    # spatial resolution in x and y in (um per pixel)\n",
    "    cell_diameter = 10                      # in microns\n",
    "    d_px = int(cell_diameter // dxy[0])     # convert microns to pixels\n",
    "\n",
    "    # CNMF parameters (optimized for Colab)\n",
    "    p = 1                                   # order of the autoregressive system (1 is more stable than 2)\n",
    "    gnb = 2                                 # number of global background components\n",
    "    merge_thr = 0.7                         # merging threshold, max correlation allowed\n",
    "    bas_nonneg = True                       # enforce nonnegativity constraint on calcium traces\n",
    "    rf = None                               # No patches - analyze full image at once\n",
    "    stride_cnmf = None                      # No patches\n",
    "    K = 150                                 # Reduced for Colab memory (was 200)\n",
    "    gSig = np.array([0.5*d_px, 0.5*d_px])  # expected half-width of neurons in pixels\n",
    "    gSiz = 2*gSig + 1                       # Gaussian kernel width and height\n",
    "    method_init = 'greedy_roi'              # initialization method (more stable than corr_pnr)\n",
    "    ssub = 1                                # spatial subsampling during initialization\n",
    "    tsub = 1                                # temporal subsampling during initialization\n",
    "\n",
    "    # parameters for component evaluation\n",
    "    min_SNR = 1.2               # signal to noise ratio for more sensitivity\n",
    "    rval_thr = 0.7              # space correlation threshold for more sensitivity\n",
    "    cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "    cnn_lowest = 0.1            # neurons with cnn probability lower than this value are rejected\n",
    "    \n",
    "    print(f\"üî¨ Biological parameters:\")\n",
    "    print(f\"  Cell diameter: {cell_diameter} Œºm = {d_px} pixels\")\n",
    "    print(f\"  No patches - analyzing full image\")\n",
    "    print(f\"  K (total components): {K}\")\n",
    "    print(f\"  gSig: {gSig}\")\n",
    "\n",
    "    # parameters dictionary\n",
    "    parameter_dict = {\n",
    "        'fnames': [mmap_path],\n",
    "        'fr': fr,\n",
    "        'dxy': dxy,\n",
    "        'decay_time': decay_time,\n",
    "        'p': p,\n",
    "        'nb': gnb,\n",
    "        'rf': rf,\n",
    "        'K': K,\n",
    "        'gSig': gSig,\n",
    "        'gSiz': gSiz,\n",
    "        'stride': stride_cnmf,\n",
    "        'method_init': method_init,\n",
    "        'rolling_sum': True,\n",
    "        'only_init': False,\n",
    "        'ssub': ssub,\n",
    "        'tsub': tsub,\n",
    "        'merge_thr': merge_thr,\n",
    "        'bas_nonneg': bas_nonneg,\n",
    "        'min_SNR': min_SNR,\n",
    "        'rval_thr': rval_thr,\n",
    "        'use_cnn': False,\n",
    "        'min_cnn_thr': cnn_thr,\n",
    "        'cnn_lowest': cnn_lowest,\n",
    "        'dims': dims,\n",
    "        'is3D': False,\n",
    "        'data_format': 'mmap',\n",
    "        'n_pixels_per_process': dims[0] * dims[1],\n",
    "        'do_merge': True,\n",
    "        'merge_thresh': merge_thr\n",
    "    }\n",
    "\n",
    "    # Create CNMFParams\n",
    "    opts = params.CNMFParams(params_dict=parameter_dict)\n",
    "    print(f\"üöÄ CNMF Parameters loaded successfully!\")\n",
    "\n",
    "    # Create CNMF object\n",
    "    cnm = cnmf.CNMF(n_processes=1, params=opts)\n",
    "    cnm.debug_visualize = False\n",
    "\n",
    "    # Run your custom CNMF wrapper\n",
    "    wrapper = CNMFWrapper(cnmf_obj=cnm, mmap_path=mmap_path, dims=dims, output_dir=output_dir)\n",
    "    \n",
    "    print(\"\\nüöÄ Starting CNMF analysis...\")\n",
    "    cnm_result = wrapper.run()\n",
    "    \n",
    "    return cnm_result, dims, T\n",
    "\n",
    "# Run the analysis\n",
    "if 'video_path' in locals() and os.path.exists(video_path):\n",
    "    # You can adjust limit_frames based on your Colab memory\n",
    "    # Set to None to use all frames, or a number like 600 to limit\n",
    "    limit_frames = 600  # Adjust this based on your memory needs\n",
    "    \n",
    "    cnmf_result, dims, total_frames = run_cnmf_analysis(\n",
    "        video_path=video_path,\n",
    "        output_dir=local_output,  # Use local for speed, will copy to Drive later\n",
    "        limit_frames=limit_frames\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úÖ CNMF Analysis completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Video file not found. Please upload your video file first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63badb19",
   "metadata": {},
   "source": [
    "## üìä Results & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_cnmf_results(cnmf_result, dims, output_dir):\n",
    "    \"\"\"Create comprehensive visualizations of CNMF results\"\"\"\n",
    "    \n",
    "    if cnmf_result is None:\n",
    "        print(\"‚ùå No CNMF results to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Get results\n",
    "    A = cnmf_result.estimates.A.toarray().reshape(dims + (-1,), order='F')\n",
    "    C = cnmf_result.estimates.C\n",
    "    \n",
    "    n_components = A.shape[2]\n",
    "    print(f\"üìä Visualizing {n_components} components\")\n",
    "    \n",
    "    # 1. Spatial Components Overview\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    fig.suptitle('Spatial Components (First 12)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i in range(min(12, n_components)):\n",
    "        ax = axes[i//4, i%4]\n",
    "        im = ax.imshow(A[:,:,i], cmap='hot', interpolation='nearest')\n",
    "        ax.set_title(f'Component {i+1}', fontsize=12)\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(min(12, n_components), 12):\n",
    "        axes[i//4, i%4].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'spatial_components.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Temporal Traces\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Plot first 10 traces with offset for visibility\n",
    "    for i in range(min(10, n_components)):\n",
    "        offset = i * 2  # Vertical offset\n",
    "        ax.plot(C[i] + offset, label=f'Component {i+1}', linewidth=1.5)\n",
    "    \n",
    "    ax.set_title('Temporal Activity Traces (First 10 Components)', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Frame Number', fontsize=14)\n",
    "    ax.set_ylabel('Fluorescence + Offset', fontsize=14)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'temporal_traces.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Component Statistics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # Activity levels\n",
    "    activity_levels = np.mean(C, axis=1)\n",
    "    axes[0,0].hist(activity_levels, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution of Component Activity Levels')\n",
    "    axes[0,0].set_xlabel('Mean Fluorescence')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    \n",
    "    # Spatial extent\n",
    "    spatial_extent = [np.count_nonzero(A[:,:,i]) for i in range(n_components)]\n",
    "    axes[0,1].hist(spatial_extent, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    axes[0,1].set_title('Distribution of Component Spatial Extent')\n",
    "    axes[0,1].set_xlabel('Number of Non-zero Pixels')\n",
    "    axes[0,1].set_ylabel('Count')\n",
    "    \n",
    "    # Activity vs Spatial Extent\n",
    "    axes[1,0].scatter(spatial_extent, activity_levels, alpha=0.6, s=50)\n",
    "    axes[1,0].set_title('Activity vs Spatial Extent')\n",
    "    axes[1,0].set_xlabel('Spatial Extent (pixels)')\n",
    "    axes[1,0].set_ylabel('Mean Activity')\n",
    "    \n",
    "    # Component quality metrics\n",
    "    max_activities = np.max(C, axis=1)\n",
    "    std_activities = np.std(C, axis=1)\n",
    "    snr_estimates = max_activities / std_activities\n",
    "    \n",
    "    axes[1,1].hist(snr_estimates, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[1,1].set_title('Estimated SNR Distribution')\n",
    "    axes[1,1].set_xlabel('Max/Std Ratio')\n",
    "    axes[1,1].set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'component_statistics.png'), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Summary Statistics\n",
    "    print(\"\\nüìà CNMF Analysis Summary:\")\n",
    "    print(f\"  üî¢ Total components found: {n_components}\")\n",
    "    print(f\"  üìê Image dimensions: {dims[0]} x {dims[1]} pixels\")\n",
    "    print(f\"  üìä Mean activity level: {np.mean(activity_levels):.3f} ¬± {np.std(activity_levels):.3f}\")\n",
    "    print(f\"  üìè Mean spatial extent: {np.mean(spatial_extent):.1f} ¬± {np.std(spatial_extent):.1f} pixels\")\n",
    "    print(f\"  üì∂ Mean estimated SNR: {np.mean(snr_estimates):.2f} ¬± {np.std(snr_estimates):.2f}\")\n",
    "    \n",
    "    # Save summary statistics\n",
    "    summary_stats = {\n",
    "        'n_components': n_components,\n",
    "        'image_dims': dims,\n",
    "        'mean_activity': float(np.mean(activity_levels)),\n",
    "        'std_activity': float(np.std(activity_levels)),\n",
    "        'mean_spatial_extent': float(np.mean(spatial_extent)),\n",
    "        'std_spatial_extent': float(np.std(spatial_extent)),\n",
    "        'mean_snr': float(np.mean(snr_estimates)),\n",
    "        'std_snr': float(np.std(snr_estimates))\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(os.path.join(output_dir, 'summary_statistics.json'), 'w') as f:\n",
    "        json.dump(summary_stats, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Visualizations saved to: {output_dir}\")\n",
    "\n",
    "# Create visualizations\n",
    "if 'cnmf_result' in locals() and cnmf_result is not None:\n",
    "    visualize_cnmf_results(cnmf_result, dims, local_output)\n",
    "else:\n",
    "    print(\"‚ùå No CNMF results available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5393c94",
   "metadata": {},
   "source": [
    "## üìÅ Stage Files Analysis\n",
    "\n",
    "Check all the debug stage files that were saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved stage files\n",
    "print(\"üìÅ Saved debug stage files:\")\n",
    "stage_files = []\n",
    "for file in os.listdir(local_output):\n",
    "    if file.endswith('.npy') and ('_after_' in file or '_final' in file):\n",
    "        stage_files.append(file)\n",
    "        file_size = os.path.getsize(os.path.join(local_output, file)) / (1024**2)\n",
    "        print(f\"  {file:<30} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Group by stage\n",
    "stages = set()\n",
    "for file in stage_files:\n",
    "    if '_after_' in file:\n",
    "        stage = file.split('_after_')[1].split('.npy')[0]\n",
    "        stages.add('after_' + stage)\n",
    "    elif '_final' in file:\n",
    "        stages.add('final')\n",
    "\n",
    "print(f\"\\nüéØ Available stages for napari viewer: {sorted(stages)}\")\n",
    "print(f\"üìä Total files: {len(stage_files)}\")\n",
    "print(f\"üíæ Total size: {sum(os.path.getsize(os.path.join(local_output, f)) for f in stage_files) / (1024**2):.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05b244",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Copy Results to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943dd716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all results to Google Drive for persistence\n",
    "print(\"‚òÅÔ∏è Copying results to Google Drive...\")\n",
    "\n",
    "for file in os.listdir(local_output):\n",
    "    src = os.path.join(local_output, file)\n",
    "    dst = os.path.join(output_dir, file)\n",
    "    \n",
    "    if os.path.isfile(src):\n",
    "        shutil.copy2(src, dst)\n",
    "        file_size = os.path.getsize(src) / (1024**2)\n",
    "        print(f\"  ‚úÖ Copied {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nüíæ All results saved to Google Drive: {output_dir}\")\n",
    "print(\"üîó You can access these files from any device via Google Drive\")\n",
    "\n",
    "# List final contents\n",
    "print(\"\\nüìÅ Final output directory contents:\")\n",
    "!ls -lh \"$output_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d21c17",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è Download Key Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22573c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download key result files\n",
    "print(\"‚¨áÔ∏è Downloading key result files...\")\n",
    "\n",
    "# Download the final HDF5 file\n",
    "hdf5_file = os.path.join(local_output, 'cnmf_final_output.hdf5')\n",
    "if os.path.exists(hdf5_file):\n",
    "    files.download(hdf5_file)\n",
    "    print(\"‚úÖ Downloaded: cnmf_final_output.hdf5\")\n",
    "\n",
    "# Download final matrices\n",
    "final_files = ['A_final.npy', 'C_final.npy', 'YrA_final.npy']\n",
    "for filename in final_files:\n",
    "    filepath = os.path.join(local_output, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        files.download(filepath)\n",
    "        print(f\"‚úÖ Downloaded: {filename}\")\n",
    "\n",
    "# Download visualizations\n",
    "viz_files = ['spatial_components.png', 'temporal_traces.png', 'component_statistics.png']\n",
    "for filename in viz_files:\n",
    "    filepath = os.path.join(local_output, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        files.download(filepath)\n",
    "        print(f\"‚úÖ Downloaded: {filename}\")\n",
    "\n",
    "# Download summary statistics\n",
    "summary_file = os.path.join(local_output, 'summary_statistics.json')\n",
    "if os.path.exists(summary_file):\n",
    "    files.download(summary_file)\n",
    "    print(\"‚úÖ Downloaded: summary_statistics.json\")\n",
    "\n",
    "print(\"\\nüéâ Download complete! Check your Downloads folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2447ba4a",
   "metadata": {},
   "source": [
    "## üîç Note: Napari Viewer\n",
    "\n",
    "**Your napari viewer code won't run directly in Colab** because Colab doesn't support interactive GUI applications. However:\n",
    "\n",
    "1. **All debug stage files are saved** - you can download them and use with your local napari viewer\n",
    "2. **Stage switching will work locally** - once you download the files to your computer\n",
    "3. **All intermediate stages are preserved** - `after_initialize`, `after_spatial_1`, etc.\n",
    "\n",
    "### To use napari locally with these results:\n",
    "1. Download all the `.npy` files from Google Drive\n",
    "2. Update your `napari_runner.py` to point to the downloaded directory\n",
    "3. Run napari locally with the stage switching functionality\n",
    "\n",
    "### Colab Alternative:\n",
    "The matplotlib visualizations above provide a good overview of your results without needing interactive napari."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f06ebf",
   "metadata": {},
   "source": [
    "## üßπ Memory Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f60da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up memory\n",
    "import gc\n",
    "\n",
    "# Delete large variables\n",
    "if 'cnmf_result' in locals():\n",
    "    del cnmf_result\n",
    "if 'A' in locals():\n",
    "    del A\n",
    "if 'C' in locals():\n",
    "    del C\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Check final memory usage\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"üßπ Memory after cleanup: {memory.percent}% used ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB)\")\n",
    "print(\"‚úÖ Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
